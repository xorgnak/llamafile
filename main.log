[1711034362] Log start
[1711034362] Cmd: /usr/local/bin/llama -m tinyllama-1.1b-chat-v1.0.Q4_0.gguf -c 2048 -b 128 -p "The time is 2024-03-21 09:19:22 -0600. What time is it?
"
[1711034364] main: seed  = 1711034364
[1711034364] main: llama backend init
[1711034365] main: load the model and apply lora adapter, if any
[1711034365] llama_model_loader: loaded meta data with 23 key-value pairs and 201 tensors from tinyllama-1.1b-chat-v1.0.Q4_0.gguf (version GGUF V3 (latest))
[1711034365] llama_model_loader: - tensor    0:                    output.weight q6_K     [  2048, 32000,     1,     1 ]
[1711034365] llama_model_loader: - tensor    1:                token_embd.weight q4_0     [  2048, 32000,     1,     1 ]
[1711034365] llama_model_loader: - tensor    2:           blk.0.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor    3:            blk.0.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor    4:            blk.0.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor    5:              blk.0.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor    6:            blk.0.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor    7:              blk.0.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor    8:         blk.0.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor    9:              blk.0.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   10:              blk.0.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   11:           blk.1.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   12:            blk.1.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   13:            blk.1.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   14:              blk.1.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   15:            blk.1.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   16:              blk.1.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   17:         blk.1.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   18:              blk.1.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   19:              blk.1.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   20:          blk.10.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   21:           blk.10.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   22:           blk.10.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   23:             blk.10.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   24:           blk.10.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   25:             blk.10.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   26:        blk.10.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   27:             blk.10.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   28:             blk.10.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   29:          blk.11.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   30:           blk.11.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   31:           blk.11.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   32:             blk.11.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   33:           blk.11.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   34:             blk.11.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   35:        blk.11.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   36:             blk.11.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   37:             blk.11.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   38:          blk.12.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   39:           blk.12.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   40:           blk.12.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   41:             blk.12.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   42:           blk.12.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   43:             blk.12.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   44:        blk.12.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   45:             blk.12.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   46:             blk.12.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   47:          blk.13.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   48:           blk.13.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   49:           blk.13.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   50:             blk.13.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   51:           blk.13.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   52:             blk.13.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   53:        blk.13.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   54:             blk.13.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   55:             blk.13.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   56:          blk.14.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   57:           blk.14.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   58:           blk.14.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   59:             blk.14.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   60:           blk.14.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   61:             blk.14.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   62:        blk.14.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   63:             blk.14.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   64:             blk.14.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   65:          blk.15.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   66:           blk.15.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   67:           blk.15.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   68:             blk.15.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   69:           blk.15.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   70:             blk.15.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   71:        blk.15.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   72:             blk.15.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   73:             blk.15.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   74:          blk.16.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   75:           blk.16.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   76:           blk.16.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   77:             blk.16.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   78:           blk.16.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   79:             blk.16.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   80:        blk.16.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   81:             blk.16.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   82:             blk.16.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   83:          blk.17.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   84:           blk.17.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   85:           blk.17.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   86:             blk.17.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   87:           blk.17.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   88:             blk.17.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   89:        blk.17.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   90:             blk.17.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   91:             blk.17.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   92:          blk.18.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   93:           blk.18.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   94:           blk.18.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   95:             blk.18.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor   96:           blk.18.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor   97:             blk.18.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor   98:        blk.18.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor   99:             blk.18.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  100:             blk.18.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  101:          blk.19.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  102:           blk.19.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  103:           blk.19.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  104:             blk.19.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  105:           blk.19.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  106:             blk.19.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  107:        blk.19.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  108:             blk.19.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  109:             blk.19.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  110:           blk.2.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  111:            blk.2.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  112:            blk.2.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  113:              blk.2.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  114:            blk.2.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  115:              blk.2.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  116:         blk.2.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  117:              blk.2.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  118:              blk.2.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  119:          blk.20.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  120:           blk.20.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  121:           blk.20.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  122:             blk.20.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  123:           blk.20.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  124:             blk.20.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  125:        blk.20.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  126:             blk.20.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  127:             blk.20.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  128:          blk.21.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  129:           blk.21.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  130:           blk.21.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  131:             blk.21.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  132:           blk.21.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  133:             blk.21.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  134:        blk.21.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  135:             blk.21.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  136:             blk.21.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  137:           blk.3.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  138:            blk.3.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  139:            blk.3.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  140:              blk.3.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  141:            blk.3.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  142:              blk.3.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  143:         blk.3.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  144:              blk.3.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  145:              blk.3.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  146:           blk.4.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  147:            blk.4.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  148:            blk.4.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  149:              blk.4.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  150:            blk.4.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  151:              blk.4.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  152:         blk.4.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  153:              blk.4.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  154:              blk.4.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  155:           blk.5.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  156:            blk.5.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  157:            blk.5.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  158:              blk.5.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  159:            blk.5.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  160:              blk.5.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  161:         blk.5.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  162:              blk.5.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  163:              blk.5.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  164:           blk.6.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  165:            blk.6.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  166:            blk.6.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  167:              blk.6.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  168:            blk.6.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  169:              blk.6.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  170:         blk.6.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  171:              blk.6.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  172:              blk.6.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  173:           blk.7.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  174:            blk.7.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  175:            blk.7.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  176:              blk.7.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  177:            blk.7.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  178:              blk.7.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  179:         blk.7.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  180:              blk.7.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  181:              blk.7.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  182:           blk.8.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  183:            blk.8.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  184:            blk.8.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  185:              blk.8.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  186:            blk.8.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  187:              blk.8.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  188:         blk.8.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  189:              blk.8.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  190:              blk.8.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  191:           blk.9.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  192:            blk.9.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  193:            blk.9.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  194:              blk.9.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1711034365] llama_model_loader: - tensor  195:            blk.9.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: - tensor  196:              blk.9.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  197:         blk.9.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  198:              blk.9.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1711034365] llama_model_loader: - tensor  199:              blk.9.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1711034365] llama_model_loader: - tensor  200:               output_norm.weight f32      [  2048,     1,     1,     1 ]
[1711034365] llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
[1711034365] llama_model_loader: - kv   0:                       general.architecture str              = llama
[1711034365] llama_model_loader: - kv   1:                               general.name str              = tinyllama_tinyllama-1.1b-chat-v1.0
[1711034365] llama_model_loader: - kv   2:                       llama.context_length u32              = 2048
[1711034365] llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048
[1711034365] llama_model_loader: - kv   4:                          llama.block_count u32              = 22
[1711034365] llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5632
[1711034365] llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 64
[1711034365] llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32
[1711034365] llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 4
[1711034365] llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
[1711034365] llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000
[1711034365] llama_model_loader: - kv  11:                          general.file_type u32              = 2
[1711034365] llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
[1711034365] llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = ["<unk>", "<s>", "</s>", "<0x00>", "<...
[1711034365] llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...
[1711034365] llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...
[1711034365] llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,61249]   = ["▁ t", "e r", "i n", "▁ a", "e n...
[1711034365] llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
[1711034365] llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
[1711034365] llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
[1711034365] llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2
[1711034365] llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}\n{% if m...
[1711034365] llama_model_loader: - kv  22:               general.quantization_version u32              = 2
[1711034365] llama_model_loader: - type  f32:   45 tensors
[1711034365] llama_model_loader: - type q4_0:  155 tensors
[1711034365] llama_model_loader: - type q6_K:    1 tensors
[1711034365] llm_load_vocab: special tokens definition check successful ( 259/32000 ).
[1711034365] llm_load_print_meta: format           = GGUF V3 (latest)
[1711034365] llm_load_print_meta: arch             = llama
[1711034365] llm_load_print_meta: vocab type       = SPM
[1711034365] llm_load_print_meta: n_vocab          = 32000
[1711034365] llm_load_print_meta: n_merges         = 0
[1711034365] llm_load_print_meta: n_ctx_train      = 2048
[1711034365] llm_load_print_meta: n_embd           = 2048
[1711034365] llm_load_print_meta: n_head           = 32
[1711034365] llm_load_print_meta: n_head_kv        = 4
[1711034365] llm_load_print_meta: n_layer          = 22
[1711034365] llm_load_print_meta: n_rot            = 64
[1711034365] llm_load_print_meta: n_gqa            = 8
[1711034365] llm_load_print_meta: f_norm_eps       = 0.0e+00
[1711034365] llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
[1711034365] llm_load_print_meta: f_clamp_kqv      = 0.0e+00
[1711034365] llm_load_print_meta: f_max_alibi_bias = 0.0e+00
[1711034365] llm_load_print_meta: n_ff             = 5632
[1711034365] llm_load_print_meta: n_expert         = 0
[1711034365] llm_load_print_meta: n_expert_used    = 0
[1711034365] llm_load_print_meta: rope scaling     = linear
[1711034365] llm_load_print_meta: freq_base_train  = 10000.0
[1711034365] llm_load_print_meta: freq_scale_train = 1
[1711034365] llm_load_print_meta: n_yarn_orig_ctx  = 2048
[1711034365] llm_load_print_meta: rope_finetuned   = unknown
[1711034365] llm_load_print_meta: model type       = ?B
[1711034365] llm_load_print_meta: model ftype      = mostly Q4_0
[1711034365] llm_load_print_meta: model params     = 1.10 B
[1711034365] llm_load_print_meta: model size       = 606.53 MiB (4.63 BPW) 
[1711034365] llm_load_print_meta: general.name     = tinyllama_tinyllama-1.1b-chat-v1.0
[1711034365] llm_load_print_meta: BOS token        = 1 '<s>'
[1711034365] llm_load_print_meta: EOS token        = 2 '</s>'
[1711034365] llm_load_print_meta: UNK token        = 0 '<unk>'
[1711034365] llm_load_print_meta: PAD token        = 2 '</s>'
[1711034365] llm_load_print_meta: LF token         = 13 '<0x0A>'
[1711034365] llm_load_tensors: ggml ctx size =    0.08 MiB
[1711034365] llm_load_tensors: mem required  =  606.61 MiB
[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] .[1711034365] 
[1711034365] llama_new_context_with_model: n_ctx      = 2048
[1711034365] llama_new_context_with_model: freq_base  = 10000.0
[1711034365] llama_new_context_with_model: freq_scale = 1
[1711034365] llama_new_context_with_model: KV self size  =   44.00 MiB, K (f16):   22.00 MiB, V (f16):   22.00 MiB
[1711034365] llama_build_graph: non-view tensors processed: 466/466
[1711034365] llama_new_context_with_model: compute buffer total size = 39.31 MiB
[1711034365] llama_new_context_with_model: VRAM scratch buffer: 36.00 MiB
[1711034365] llama_new_context_with_model: total VRAM used: 36.00 MiB (model: 0.00 MiB, context: 36.00 MiB)
[1711034365] warming up the model with an empty run
[1711034386] n_ctx: 2048
[1711034386] 
[1711034386] system_info: n_threads = 4 / 4 | AVX = 1 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | 
[1711034386] add_bos: 1
[1711034386] tokenize the prompt
[1711034386] prompt: "The time is 2024-03-21 09:19:22 -0600. What time is it?
"
[1711034386] tokens: [ '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13 ]
[1711034386] recalculate the cached logits (check): embd_inp.empty() false, n_matching_session_tokens 0, embd_inp.size() 36, session_tokens.size() 0, embd_inp.size() 36
[1711034386] inp_pfx: [ '':1, ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Inst':2799, 'ruction':4080, ':':29901, '':13, '':13 ]
[1711034386] inp_sfx: [ ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Response':13291, ':':29901, '':13, '':13 ]
[1711034386] cml_pfx: [ '':1, ' ':29871, '':13, '<':29966, '|':29989, 'im':326, '_':29918, 'start':2962, '|':29989, '>':29958, 'user':1792, '':13 ]
[1711034386] cml_sfx: [ ' <':529, '|':29989, 'im':326, '_':29918, 'end':355, '|':29989, '>':29958, '':13, '<':29966, '|':29989, 'im':326, '_':29918, 'start':2962, '|':29989, '>':29958, 'ass':465, 'istant':22137, '':13 ]
[1711034386] sampling: 
	repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000
	top_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800
	mirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000
[1711034386] sampling order: 
CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temp 
[1711034386] generate: n_ctx = 2048, n_batch = 128, n_predict = -1, n_keep = 0
[1711034386] 

[1711034386] embd_inp.size(): 36, n_consumed: 0
[1711034386] eval: [ '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13 ]
[1711034403] n_past = 36
[1711034403] sampled token:  3421: 'My'
[1711034403] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421 ]
[1711034403] n_remain: -2
[1711034403] eval: [ 'My':3421 ]
[1711034403] n_past = 37
[1711034403] sampled token:   931: ' time'
[1711034403] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931 ]
[1711034403] n_remain: -3
[1711034403] eval: [ ' time':931 ]
[1711034404] n_past = 38
[1711034404] sampled token:   338: ' is'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338 ]
[1711034404] n_remain: -4
[1711034404] eval: [ ' is':338 ]
[1711034404] n_past = 39
[1711034404] sampled token: 29871: ' '
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871 ]
[1711034404] n_remain: -5
[1711034404] eval: [ ' ':29871 ]
[1711034404] n_past = 40
[1711034404] sampled token: 29906: '2'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906 ]
[1711034404] n_remain: -6
[1711034404] eval: [ '2':29906 ]
[1711034404] n_past = 41
[1711034404] sampled token: 29900: '0'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900 ]
[1711034404] n_remain: -7
[1711034404] eval: [ '0':29900 ]
[1711034404] n_past = 42
[1711034404] sampled token: 29906: '2'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906 ]
[1711034404] n_remain: -8
[1711034404] eval: [ '2':29906 ]
[1711034404] n_past = 43
[1711034404] sampled token: 29946: '4'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946 ]
[1711034404] n_remain: -9
[1711034404] eval: [ '4':29946 ]
[1711034404] n_past = 44
[1711034404] sampled token: 29899: '-'
[1711034404] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899 ]
[1711034404] n_remain: -10
[1711034404] eval: [ '-':29899 ]
[1711034405] n_past = 45
[1711034405] sampled token: 29900: '0'
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900 ]
[1711034405] n_remain: -11
[1711034405] eval: [ '0':29900 ]
[1711034405] n_past = 46
[1711034405] sampled token: 29941: '3'
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941 ]
[1711034405] n_remain: -12
[1711034405] eval: [ '3':29941 ]
[1711034405] n_past = 47
[1711034405] sampled token: 29899: '-'
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899 ]
[1711034405] n_remain: -13
[1711034405] eval: [ '-':29899 ]
[1711034405] n_past = 48
[1711034405] sampled token: 29906: '2'
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906 ]
[1711034405] n_remain: -14
[1711034405] eval: [ '2':29906 ]
[1711034405] n_past = 49
[1711034405] sampled token: 29896: '1'
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896 ]
[1711034405] n_remain: -15
[1711034405] eval: [ '1':29896 ]
[1711034405] n_past = 50
[1711034405] sampled token: 29871: ' '
[1711034405] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871 ]
[1711034405] n_remain: -16
[1711034405] eval: [ ' ':29871 ]
[1711034406] n_past = 51
[1711034406] sampled token: 29900: '0'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900 ]
[1711034406] n_remain: -17
[1711034406] eval: [ '0':29900 ]
[1711034406] n_past = 52
[1711034406] sampled token: 29929: '9'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929 ]
[1711034406] n_remain: -18
[1711034406] eval: [ '9':29929 ]
[1711034406] n_past = 53
[1711034406] sampled token: 29901: ':'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901 ]
[1711034406] n_remain: -19
[1711034406] eval: [ ':':29901 ]
[1711034406] n_past = 54
[1711034406] sampled token: 29896: '1'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896 ]
[1711034406] n_remain: -20
[1711034406] eval: [ '1':29896 ]
[1711034406] n_past = 55
[1711034406] sampled token: 29929: '9'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929 ]
[1711034406] n_remain: -21
[1711034406] eval: [ '9':29929 ]
[1711034406] n_past = 56
[1711034406] sampled token: 29901: ':'
[1711034406] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901 ]
[1711034406] n_remain: -22
[1711034406] eval: [ ':':29901 ]
[1711034407] n_past = 57
[1711034407] sampled token: 29906: '2'
[1711034407] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906 ]
[1711034407] n_remain: -23
[1711034407] eval: [ '2':29906 ]
[1711034407] n_past = 58
[1711034407] sampled token: 29906: '2'
[1711034407] last: [ '':0, '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906 ]
[1711034407] n_remain: -24
[1711034407] eval: [ '2':29906 ]
[1711034407] n_past = 59
[1711034407] sampled token:   448: ' -'
[1711034407] last: [ '':0, '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448 ]
[1711034407] n_remain: -25
[1711034407] eval: [ ' -':448 ]
[1711034407] n_past = 60
[1711034407] sampled token: 29900: '0'
[1711034407] last: [ '':0, '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900 ]
[1711034407] n_remain: -26
[1711034407] eval: [ '0':29900 ]
[1711034407] n_past = 61
[1711034407] sampled token: 29953: '6'
[1711034407] last: [ '':0, '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953 ]
[1711034407] n_remain: -27
[1711034407] eval: [ '6':29953 ]
[1711034407] n_past = 62
[1711034407] sampled token: 29900: '0'
[1711034407] last: [ '':0, '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900 ]
[1711034407] n_remain: -28
[1711034407] eval: [ '0':29900 ]
[1711034408] n_past = 63
[1711034408] sampled token: 29900: '0'
[1711034408] last: [ '':1, ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900 ]
[1711034408] n_remain: -29
[1711034408] eval: [ '0':29900 ]
[1711034408] n_past = 64
[1711034408] sampled token: 29889: '.'
[1711034408] last: [ ' The':450, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889 ]
[1711034408] n_remain: -30
[1711034408] eval: [ '.':29889 ]
[1711034408] n_past = 65
[1711034408] sampled token: 16564: ' Based'
[1711034408] last: [ ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564 ]
[1711034408] n_remain: -31
[1711034408] eval: [ ' Based':16564 ]
[1711034408] n_past = 66
[1711034408] sampled token:   373: ' on'
[1711034408] last: [ ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373 ]
[1711034408] n_remain: -32
[1711034408] eval: [ ' on':373 ]
[1711034408] n_past = 67
[1711034408] sampled token:   278: ' the'
[1711034408] last: [ ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278 ]
[1711034408] n_remain: -33
[1711034408] eval: [ ' the':278 ]
[1711034408] n_past = 68
[1711034408] sampled token: 13382: ' passage'
[1711034408] last: [ '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382 ]
[1711034408] n_remain: -34
[1711034408] eval: [ ' passage':13382 ]
[1711034409] n_past = 69
[1711034409] sampled token:  2038: ' above'
[1711034409] last: [ '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038 ]
[1711034409] n_remain: -35
[1711034409] eval: [ ' above':2038 ]
[1711034409] n_past = 70
[1711034409] sampled token: 29892: ','
[1711034409] last: [ '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892 ]
[1711034409] n_remain: -36
[1711034409] eval: [ ',':29892 ]
[1711034409] n_past = 71
[1711034409] sampled token:  1128: ' How'
[1711034409] last: [ '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128 ]
[1711034409] n_remain: -37
[1711034409] eval: [ ' How':1128 ]
[1711034409] n_past = 72
[1711034409] sampled token:   947: ' does'
[1711034409] last: [ '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947 ]
[1711034409] n_remain: -38
[1711034409] eval: [ ' does':947 ]
[1711034409] n_past = 73
[1711034409] sampled token:   278: ' the'
[1711034409] last: [ '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278 ]
[1711034409] n_remain: -39
[1711034409] eval: [ ' the':278 ]
[1711034410] n_past = 74
[1711034410] sampled token:  4148: ' author'
[1711034410] last: [ '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148 ]
[1711034410] n_remain: -40
[1711034410] eval: [ ' author':4148 ]
[1711034410] n_past = 75
[1711034410] sampled token: 29915: '''
[1711034410] last: [ '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915 ]
[1711034410] n_remain: -41
[1711034410] eval: [ ''':29915 ]
[1711034410] n_past = 76
[1711034410] sampled token: 29879: 's'
[1711034410] last: [ '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879 ]
[1711034410] n_remain: -42
[1711034410] eval: [ 's':29879 ]
[1711034410] n_past = 77
[1711034410] sampled token:   931: ' time'
[1711034410] last: [ '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931 ]
[1711034410] n_remain: -43
[1711034410] eval: [ ' time':931 ]
[1711034410] n_past = 78
[1711034410] sampled token: 29279: ' relate'
[1711034410] last: [ ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279 ]
[1711034410] n_remain: -44
[1711034410] eval: [ ' relate':29279 ]
[1711034410] n_past = 79
[1711034410] sampled token:   304: ' to'
[1711034410] last: [ '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304 ]
[1711034410] n_remain: -45
[1711034410] eval: [ ' to':304 ]
[1711034411] n_past = 80
[1711034411] sampled token:  1009: ' their'
[1711034411] last: [ '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009 ]
[1711034411] n_remain: -46
[1711034411] eval: [ ' their':1009 ]
[1711034411] n_past = 81
[1711034411] sampled token:  1857: ' current'
[1711034411] last: [ ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857 ]
[1711034411] n_remain: -47
[1711034411] eval: [ ' current':1857 ]
[1711034411] n_past = 82
[1711034411] sampled token:  4423: ' location'
[1711034411] last: [ '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423 ]
[1711034411] n_remain: -48
[1711034411] eval: [ ' location':4423 ]
[1711034411] n_past = 83
[1711034411] sampled token:   322: ' and'
[1711034411] last: [ '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322 ]
[1711034411] n_remain: -49
[1711034411] eval: [ ' and':322 ]
[1711034411] n_past = 84
[1711034411] sampled token:   278: ' the'
[1711034411] last: [ ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278 ]
[1711034411] n_remain: -50
[1711034411] eval: [ ' the':278 ]
[1711034411] n_past = 85
[1711034411] sampled token:  2635: ' date'
[1711034411] last: [ '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635 ]
[1711034411] n_remain: -51
[1711034411] eval: [ ' date':2635 ]
[1711034412] n_past = 86
[1711034412] sampled token:  1641: ' being'
[1711034412] last: [ '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641 ]
[1711034412] n_remain: -52
[1711034412] eval: [ ' being':1641 ]
[1711034412] n_past = 87
[1711034412] sampled token:  5276: ' mentioned'
[1711034412] last: [ ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276 ]
[1711034412] n_remain: -53
[1711034412] eval: [ ' mentioned':5276 ]
[1711034412] n_past = 88
[1711034412] sampled token:   297: ' in'
[1711034412] last: [ '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276, ' in':297 ]
[1711034412] n_remain: -54
[1711034412] eval: [ ' in':297 ]
[1711034412] n_past = 89
[1711034412] sampled token:   278: ' the'
[1711034412] last: [ '6':29953, '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276, ' in':297, ' the':278 ]
[1711034412] n_remain: -55
[1711034412] eval: [ ' the':278 ]
[1711034412] n_past = 90
[1711034412] sampled token:  1426: ' text'
[1711034412] last: [ '0':29900, '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276, ' in':297, ' the':278, ' text':1426 ]
[1711034412] n_remain: -56
[1711034412] eval: [ ' text':1426 ]
[1711034413] n_past = 91
[1711034413] sampled token: 29973: '?'
[1711034413] last: [ '0':29900, '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276, ' in':297, ' the':278, ' text':1426, '?':29973 ]
[1711034413] n_remain: -57
[1711034413] eval: [ '?':29973 ]
[1711034413] n_past = 92
[1711034413] sampled token:     2: ''
[1711034413] last: [ '.':29889, ' What':1724, ' time':931, ' is':338, ' it':372, '?':29973, '':13, 'My':3421, ' time':931, ' is':338, ' ':29871, '2':29906, '0':29900, '2':29906, '4':29946, '-':29899, '0':29900, '3':29941, '-':29899, '2':29906, '1':29896, ' ':29871, '0':29900, '9':29929, ':':29901, '1':29896, '9':29929, ':':29901, '2':29906, '2':29906, ' -':448, '0':29900, '6':29953, '0':29900, '0':29900, '.':29889, ' Based':16564, ' on':373, ' the':278, ' passage':13382, ' above':2038, ',':29892, ' How':1128, ' does':947, ' the':278, ' author':4148, ''':29915, 's':29879, ' time':931, ' relate':29279, ' to':304, ' their':1009, ' current':1857, ' location':4423, ' and':322, ' the':278, ' date':2635, ' being':1641, ' mentioned':5276, ' in':297, ' the':278, ' text':1426, '?':29973, '':2 ]
[1711034413] n_remain: -58
[1711034413] found EOS token
[1711034413]  [end of text]
[1711034413] 
[1711034413] llama_print_timings:        load time =   20864.11 ms
[1711034413] llama_print_timings:      sample time =      63.77 ms /    57 runs   (    1.12 ms per token,   893.80 tokens per second)
[1711034413] llama_print_timings: prompt eval time =   17429.96 ms /    36 tokens (  484.17 ms per token,     2.07 tokens per second)
[1711034413] llama_print_timings:        eval time =    9591.44 ms /    56 runs   (  171.28 ms per token,     5.84 tokens per second)
[1711034413] llama_print_timings:       total time =   27180.78 ms
[1711034413] Log end
